---
title: "ADS Project 4 Team12"
author: "Kexin Nie, Kai Chen, Senyao Han, Yini Zhang, Chenyun Zhu"
date: "April 13, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction
In this entity resolution project. We studied two papers (No.2 and No.5) about entity resolution and tried to understand their algorism. We also compared the two methods. We believe that our work is significant for people who want to have a better understand of these two papers. The following are the details of our works.

## Part I Simple Linear Support Vector Machine
SVM is one of the most popular tools of classification. In paper 2, the author introduced the use of simple linear svm for a multi-classification. They first divided the data set into test and training set by seperating data with same label into two groups with same size. Then they calculate the test prediction errors. The accuracy rate is simply the porpotion of right match in the test set.
For the features selection, since the author of paper doesn't point out a specific way to choose features, we decide to use the sample code on Github. Also, at the end we caculated the mean and standard deviation of accuracy of all our data set and compared the performance of variable Coauthor, Paper and Journal.
# 1.0 Packages Install
```{r}
install.packages("pacman")
pacman::p_load(text2vec, dplyr, qlcMatrix, kernlab, knitr)
install.packages("e1071")

```
# 1.1 Input data and feature selection

```{r}
library(e1071)
library(pacman)
#Our feature fuction
get_feature<-function(data, condition="combine"){
  if (!require("pacman")) install.packages("pacman")
  pacman::p_load(text2vec, dplyr, qlcMatrix, kernlab, knitr)
  if (condition=="coauthor"){
    it_train <- itoken(data$Coauthor,
                       preprocessor = tolower,
                       tokenizer = word_tokenizer,
                       ids = data$PaperID,
                       # turn off progressbar because it won't look nice in rmd
                       progressbar = FALSE)
  }else if(condition=="paper"){
    it_train <- itoken(data$Paper,
                       preprocessor = tolower,
                       tokenizer = word_tokenizer,
                       ids = data$PaperID,
                       # turn off progressbar because it won't look nice in rmd
                       progressbar = FALSE)
  } else if(condition=="journal"){
    it_train <- itoken(data$Journal,
                       preprocessor = tolower,
                       tokenizer = word_tokenizer,
                       ids = data$PaperID,
                       # turn off progressbar because it won't look nice in rmd
                       progressbar = FALSE)
  } else{
    combine<-paste(data$Paper, data$Coauthor, data$Journal)
    it_train <- itoken(combine,
                       preprocessor = tolower,
                       tokenizer = word_tokenizer,
                       ids = data$PaperID,
                       # turn off progressbar because it won't look nice in rmd
                       progressbar = FALSE)
  }
  
  vocab <- create_vocabulary(it_train, stopwords = c("a", "an", "the", "in", "on",
                                                     "at", "of", "above", "under"))
  #vocab
  vectorizer <- vocab_vectorizer(vocab)
  dtm_train <- create_dtm(it_train, vectorizer)
  tfidf <- TfIdf$new()
  dtm_train_tfidf <- fit_transform(dtm_train, tfidf)
  docsdissim <- cosSparse(t(dtm_train_tfidf))
  y<-as.data.frame(as.matrix(docsdissim))
  y$label<-as.factor(data$AuthorID)
  return(y)
  #result_sclust <- specc(as.matrix(dtm_train_tfidf),
  # centers=length(unique(data$AuthorID)))
  #return(result_sclust)
  
}

my.dir<-"C:/Users/sh355/Desktop/columbia/2nd Semester/Applied Data Science/Spr2017-proj4-team12/output/Coauthor_No_Space_Author"
files<-list.files(my.dir)
path<-file.path(my.dir, files)
n<-length(path)
names<-gsub(".csv", "", files)

Data<-list()
n<-1
for (i in path){
  Data[[n]]<-read.csv(i, header = T, stringsAsFactors = FALSE)
  n<-n+1
}

feature_paper<-list()
feature_coauthor<-list()
feature_journal<-list()
feature_combine<-list()
feature_paper<-lapply(Data, get_feature, condition="paper")
feature_coauthor<-lapply(Data, get_feature, condition="coauthor")
feature_journal<-lapply(Data, get_feature, condition="journal")
feature_combine<-lapply(Data, get_feature)

feature_coauthor[is.na(feature_coauthor)]<-0
feature_combine[is.na(feature_combine)]<-0
```
```{r}
entity<-function(data){
  en<-nrow(data)/length(unique(data$AuthorID))
  return(en)
}
```
```{r}
mean_entity<-lapply(Data, entity)
```
# 1.2 Linear SVM
To understand the basic idea of svm, please visit:
http://www.cs.columbia.edu/~kathy/cs4701/documents/jason_svm_tutorial.pdf

```{r}
get_svm_result<-function(data){
library(e1071)
train<-c()
test<-c()
author<-unique(data$label)
for (i in author){
  d<-data[data$label==i,]
  n<-nrow(d)
  c<-0.5*n
  sample<-sample(1:n,c)
  test<-rbind(test, d[sample,])
  train<-rbind(train, d[-sample,])
}
#Tune 

tuneResult <- tune(svm, label ~ .,  data = train, kernel="linear",
                     ranges = list(gamma = 10^(-6:-1), cost = 10^(-1:1)))

bestmodel <- tuneResult$best.model
g<-bestmodel$gamma
c<-bestmodel$cost
#svm.pre<-predict(bestmodel,test)
model1<-svm(label~.,data=train,gamma=g,cost=c, kernel="linear")
svm.pre<-predict(model1,test)
test.error<-sum(svm.pre!=test$label)/nrow(test)
Accuracy=1-test.error
#CV Errors
#model<-svm(label~.,data=train,gamma=g,cost=c, cross=5)
#Ave.acc<-model$tot.accuracy
#SD.acc<-sd(model$accuracies)

return(Accuracy)

}
```

```{r}
start.time <- Sys.time()
result_paper<-lapply(feature_paper, get_svm_result)
end.time <- Sys.time()
time_svm_paper<- end.time - start.time
```
```{r}
start.time <- Sys.time()
result_coauthor<-lapply(feature_coauthor, get_svm_result)
end.time <- Sys.time()
time_svm_coauthor<- end.time - start.time
```
```{r}
start.time <- Sys.time()
result_journal<-lapply(feature_journal, get_svm_result)
end.time <- Sys.time()
time_svm_journal<- end.time - start.time
```
```{r}
start.time <- Sys.time()
result_combine<-lapply(feature_combine, get_svm_result)
end.time <- Sys.time()
time_svm_combine<- end.time - start.time
```


# 1.3 Results and Evaluation
As the results shown below, we can see column XXXXX has the best performance among the three columns.
```{r}
result_p<-unlist(result_paper)
mean_paper<-mean(result_p)
sd_paper<-sd(result_p)
mean_time<-time_svm_journal/14
```
```{r}
result_j<-unlist(result_journal)
mean_journal<-mean(result_j)
sd_journal<-sd(result_j)
mean_time<-time_svm_journal/14
```
```{r}
result_coauthor<-unlist(result_coauthor)
mean_coauthor<-mean(result_coauthor)
sd_coauthor<-sd(result_coauthor)
mean_time<-time_svm_coauthor/14
```

```{r}
result_combine<-unlist(result_combine)
mean_combine<-mean(result_combine)
sd_combine<-sd(result_combine)
mean_time<-time_svm_combine/14
```

## Part II (Please insert Title)
## Camparism and Conclusion

# 1.1 Input data and feature selection
